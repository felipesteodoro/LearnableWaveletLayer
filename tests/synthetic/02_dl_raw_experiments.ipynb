{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd1b813",
   "metadata": {},
   "source": [
    "# üß† Experimentos Deep Learning - Sinal Raw\n",
    "\n",
    "## Objetivo\n",
    "Avaliar modelos de Deep Learning usando o sinal raw (sem pr√©-processamento wavelet):\n",
    "- **CNN** (Convolutional Neural Network)\n",
    "- **LSTM** (Long Short-Term Memory)\n",
    "- **CNN-LSTM** (H√≠brido)\n",
    "- **Transformer**\n",
    "\n",
    "## Pipeline\n",
    "1. Carregar dados\n",
    "2. Preparar para DL (adicionar dimens√£o de canal)\n",
    "3. Treinar cada modelo com early stopping\n",
    "4. Avaliar no conjunto de teste\n",
    "5. Comparar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU dispon√≠vel: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Imports locais\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from src.models import (\n",
    "    create_cnn_model, create_lstm_model, \n",
    "    create_cnn_lstm_model, create_transformer_model,\n",
    "    get_callbacks\n",
    ")\n",
    "from src.evaluation import RegressionEvaluator, ResultsManager\n",
    "from src.visualization import ExperimentVisualizer\n",
    "from config.experiment_config import (\n",
    "    DATA_DIR, RESULTS_DIR, MODELS_DIR,\n",
    "    DL_TRAINING_CONFIG, DL_MODELS_CONFIG\n",
    ")\n",
    "\n",
    "# Configura√ß√£o\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS_DIR / \"dl_raw_experiments\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\n‚úÖ Imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf92d69",
   "metadata": {},
   "source": [
    "## 1. Carregar e Preparar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a620f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar datasets\n",
    "X_train = np.load(DATA_DIR / \"X_train.npy\")\n",
    "y_train = np.load(DATA_DIR / \"y_train.npy\")\n",
    "X_val = np.load(DATA_DIR / \"X_val.npy\")\n",
    "y_val = np.load(DATA_DIR / \"y_val.npy\")\n",
    "X_test = np.load(DATA_DIR / \"X_test.npy\")\n",
    "y_test = np.load(DATA_DIR / \"y_test.npy\")\n",
    "\n",
    "# Adicionar dimens√£o de canal para CNN/LSTM\n",
    "X_train = X_train[..., np.newaxis]  # (N, seq_len, 1)\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(f\"üì¶ Dados Carregados (com canal):\")\n",
    "print(f\"  Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  Val:   X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"  Test:  X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "print(f\"\\nInput shape para modelos: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669f27c",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7643b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerenciadores\n",
    "results_manager = ResultsManager(RESULTS_DIR / \"dl_raw_experiments\")\n",
    "evaluator = RegressionEvaluator()\n",
    "visualizer = ExperimentVisualizer()\n",
    "\n",
    "# Configura√ß√£o de treinamento\n",
    "training_config = DL_TRAINING_CONFIG.copy()\n",
    "print(\"Configura√ß√£o de Treinamento:\")\n",
    "for k, v in training_config.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Armazenar resultados\n",
    "all_results = {}\n",
    "all_histories = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f55cc9",
   "metadata": {},
   "source": [
    "## 3. Experimento 1: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üîµ Experimento: CNN com Sinal Raw\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Criar modelo\n",
    "cnn_params = DL_MODELS_CONFIG['CNN']\n",
    "model_cnn = create_cnn_model(input_shape, params=cnn_params)\n",
    "model_cnn.summary()\n",
    "\n",
    "# Callbacks\n",
    "model_path = str(MODELS_DIR / \"raw_cnn_best.keras\")\n",
    "callbacks = get_callbacks(model_path, patience_early=15, patience_lr=7)\n",
    "\n",
    "# Treinar\n",
    "t0 = time.time()\n",
    "history_cnn = model_cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=training_config['epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_cnn = model_cnn.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# M√©tricas\n",
    "cnn_metrics = evaluator.evaluate(y_test, y_pred_cnn)\n",
    "\n",
    "print(f\"\\nüìä Resultados CNN (Raw):\")\n",
    "print(f\"  RMSE: {cnn_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {cnn_metrics['mae']:.6f}\")\n",
    "print(f\"  R¬≤:   {cnn_metrics['r2']:.6f}\")\n",
    "print(f\"  Tempo: {elapsed:.2f}s, Epochs: {len(history_cnn.history['loss'])}\")\n",
    "\n",
    "all_results['Raw_CNN'] = {\n",
    "    'metrics': cnn_metrics,\n",
    "    'time': elapsed,\n",
    "    'epochs': len(history_cnn.history['loss']),\n",
    "    'y_pred': y_pred_cnn,\n",
    "    'params': model_cnn.count_params()\n",
    "}\n",
    "all_histories['Raw_CNN'] = history_cnn.history\n",
    "\n",
    "results_manager.log_experiment(\n",
    "    'DL_Raw', 'CNN', cnn_metrics,\n",
    "    {'params': cnn_params}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98f4b9",
   "metadata": {},
   "source": [
    "## 4. Experimento 2: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üîµ Experimento: LSTM com Sinal Raw\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Criar modelo\n",
    "lstm_params = DL_MODELS_CONFIG['LSTM']\n",
    "model_lstm = create_lstm_model(input_shape, params=lstm_params)\n",
    "model_lstm.summary()\n",
    "\n",
    "# Callbacks\n",
    "model_path = str(MODELS_DIR / \"raw_lstm_best.keras\")\n",
    "callbacks = get_callbacks(model_path, patience_early=15, patience_lr=7)\n",
    "\n",
    "# Treinar\n",
    "t0 = time.time()\n",
    "history_lstm = model_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=training_config['epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_lstm = model_lstm.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# M√©tricas\n",
    "lstm_metrics = evaluator.evaluate(y_test, y_pred_lstm)\n",
    "\n",
    "print(f\"\\nüìä Resultados LSTM (Raw):\")\n",
    "print(f\"  RMSE: {lstm_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {lstm_metrics['mae']:.6f}\")\n",
    "print(f\"  R¬≤:   {lstm_metrics['r2']:.6f}\")\n",
    "print(f\"  Tempo: {elapsed:.2f}s, Epochs: {len(history_lstm.history['loss'])}\")\n",
    "\n",
    "all_results['Raw_LSTM'] = {\n",
    "    'metrics': lstm_metrics,\n",
    "    'time': elapsed,\n",
    "    'epochs': len(history_lstm.history['loss']),\n",
    "    'y_pred': y_pred_lstm,\n",
    "    'params': model_lstm.count_params()\n",
    "}\n",
    "all_histories['Raw_LSTM'] = history_lstm.history\n",
    "\n",
    "results_manager.log_experiment(\n",
    "    'DL_Raw', 'LSTM', lstm_metrics,\n",
    "    {'params': lstm_params}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa1179",
   "metadata": {},
   "source": [
    "## 5. Experimento 3: CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üîµ Experimento: CNN-LSTM com Sinal Raw\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Criar modelo\n",
    "cnn_lstm_params = DL_MODELS_CONFIG['CNN_LSTM']\n",
    "model_cnn_lstm = create_cnn_lstm_model(input_shape, params=cnn_lstm_params)\n",
    "model_cnn_lstm.summary()\n",
    "\n",
    "# Callbacks\n",
    "model_path = str(MODELS_DIR / \"raw_cnn_lstm_best.keras\")\n",
    "callbacks = get_callbacks(model_path, patience_early=15, patience_lr=7)\n",
    "\n",
    "# Treinar\n",
    "t0 = time.time()\n",
    "history_cnn_lstm = model_cnn_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=training_config['epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_cnn_lstm = model_cnn_lstm.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# M√©tricas\n",
    "cnn_lstm_metrics = evaluator.evaluate(y_test, y_pred_cnn_lstm)\n",
    "\n",
    "print(f\"\\nüìä Resultados CNN-LSTM (Raw):\")\n",
    "print(f\"  RMSE: {cnn_lstm_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {cnn_lstm_metrics['mae']:.6f}\")\n",
    "print(f\"  R¬≤:   {cnn_lstm_metrics['r2']:.6f}\")\n",
    "print(f\"  Tempo: {elapsed:.2f}s, Epochs: {len(history_cnn_lstm.history['loss'])}\")\n",
    "\n",
    "all_results['Raw_CNN_LSTM'] = {\n",
    "    'metrics': cnn_lstm_metrics,\n",
    "    'time': elapsed,\n",
    "    'epochs': len(history_cnn_lstm.history['loss']),\n",
    "    'y_pred': y_pred_cnn_lstm,\n",
    "    'params': model_cnn_lstm.count_params()\n",
    "}\n",
    "all_histories['Raw_CNN_LSTM'] = history_cnn_lstm.history\n",
    "\n",
    "results_manager.log_experiment(\n",
    "    'DL_Raw', 'CNN_LSTM', cnn_lstm_metrics,\n",
    "    {'params': cnn_lstm_params}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36ee40",
   "metadata": {},
   "source": [
    "## 6. Experimento 4: Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üîµ Experimento: Transformer com Sinal Raw\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Criar modelo\n",
    "transformer_params = DL_MODELS_CONFIG['Transformer']\n",
    "model_transformer = create_transformer_model(input_shape, params=transformer_params)\n",
    "model_transformer.summary()\n",
    "\n",
    "# Callbacks\n",
    "model_path = str(MODELS_DIR / \"raw_transformer_best.keras\")\n",
    "callbacks = get_callbacks(model_path, patience_early=15, patience_lr=7)\n",
    "\n",
    "# Treinar\n",
    "t0 = time.time()\n",
    "history_transformer = model_transformer.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=training_config['epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_transformer = model_transformer.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# M√©tricas\n",
    "transformer_metrics = evaluator.evaluate(y_test, y_pred_transformer)\n",
    "\n",
    "print(f\"\\nüìä Resultados Transformer (Raw):\")\n",
    "print(f\"  RMSE: {transformer_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {transformer_metrics['mae']:.6f}\")\n",
    "print(f\"  R¬≤:   {transformer_metrics['r2']:.6f}\")\n",
    "print(f\"  Tempo: {elapsed:.2f}s, Epochs: {len(history_transformer.history['loss'])}\")\n",
    "\n",
    "all_results['Raw_Transformer'] = {\n",
    "    'metrics': transformer_metrics,\n",
    "    'time': elapsed,\n",
    "    'epochs': len(history_transformer.history['loss']),\n",
    "    'y_pred': y_pred_transformer,\n",
    "    'params': model_transformer.count_params()\n",
    "}\n",
    "all_histories['Raw_Transformer'] = history_transformer.history\n",
    "\n",
    "results_manager.log_experiment(\n",
    "    'DL_Raw', 'Transformer', transformer_metrics,\n",
    "    {'params': transformer_params}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de685a1",
   "metadata": {},
   "source": [
    "## 7. Compara√ß√£o dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame comparativo\n",
    "comparison_data = []\n",
    "for model_name, result in all_results.items():\n",
    "    row = {\n",
    "        'Model': model_name,\n",
    "        'RMSE': result['metrics']['rmse'],\n",
    "        'MAE': result['metrics']['mae'],\n",
    "        'R¬≤': result['metrics']['r2'],\n",
    "        'Params': result['params'],\n",
    "        'Time (s)': result['time'],\n",
    "        'Epochs': result['epochs']\n",
    "    }\n",
    "    comparison_data.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä COMPARA√á√ÉO FINAL - Deep Learning com Sinal Raw\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Salvar\n",
    "comparison_df.to_csv(RESULTS_DIR / \"dl_raw_experiments\" / \"comparison_dl_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o comparativa\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics_to_plot = ['RMSE', 'MAE', 'R¬≤']\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    data = comparison_df.set_index('Model')[metric].sort_values(\n",
    "        ascending=(metric != 'R¬≤')\n",
    "    )\n",
    "    bars = axes[idx].barh(data.index, data.values, color=colors[:len(data)])\n",
    "    axes[idx].set_xlabel(metric)\n",
    "    axes[idx].set_title(f'Compara√ß√£o: {metric}')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    for bar, val in zip(bars, data.values):\n",
    "        axes[idx].text(val, bar.get_y() + bar.get_height()/2,\n",
    "                      f'{val:.4f}', va='center', ha='left', fontsize=9)\n",
    "\n",
    "plt.suptitle('Deep Learning com Sinal Raw', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"dl_raw_experiments\" / \"comparison_dl_raw.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff32f0",
   "metadata": {},
   "source": [
    "## 8. Hist√≥rico de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5783d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de hist√≥ricos de treinamento\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_name, history) in enumerate(all_histories.items()):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(history['loss'], label='Train Loss')\n",
    "    ax.plot(history['val_loss'], label='Val Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss (MSE)')\n",
    "    ax.set_title(f'{model_name} - Training History')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Hist√≥rico de Treinamento - DL Raw', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"dl_raw_experiments\" / \"training_history.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1108a9f",
   "metadata": {},
   "source": [
    "## 9. An√°lise de Predi√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar melhor modelo\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_result = all_results[best_model_name]\n",
    "\n",
    "print(f\"\\nüèÜ Melhor Modelo: {best_model_name}\")\n",
    "\n",
    "# Plot de predi√ß√µes\n",
    "fig = visualizer.plot_prediction_comparison(\n",
    "    y_test, best_result['y_pred'],\n",
    "    model_name=best_model_name,\n",
    "    n_samples=500,\n",
    "    save_path=RESULTS_DIR / \"dl_raw_experiments\" / f\"predictions_{best_model_name}.png\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b48ce",
   "metadata": {},
   "source": [
    "## 10. Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã RESUMO - Experimentos DL com Sinal Raw\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n‚úÖ Modelos avaliados: {len(all_results)}\")\n",
    "print(f\"‚úÖ Melhor modelo: {best_model_name}\")\n",
    "print(f\"‚úÖ Melhor RMSE: {comparison_df.iloc[0]['RMSE']:.6f}\")\n",
    "print(f\"‚úÖ Melhor R¬≤: {comparison_df.iloc[0]['R¬≤']:.6f}\")\n",
    "print(f\"\\nüìÅ Resultados salvos em: {RESULTS_DIR / 'dl_raw_experiments'}\")\n",
    "print(\"\\nüéâ Notebook conclu√≠do com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
