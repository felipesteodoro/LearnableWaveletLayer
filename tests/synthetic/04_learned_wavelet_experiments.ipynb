{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa34bb0",
   "metadata": {},
   "source": [
    "# üéì Experimentos com Learned Wavelet (LearnedWaveletDWT1D_QMF)\n",
    "\n",
    "## Objetivo\n",
    "Avaliar o impacto de usar wavelets aprendidas (end-to-end) vs wavelets fixas:\n",
    "- **LearnedWavelet + CNN**\n",
    "- **LearnedWavelet + LSTM**\n",
    "- **LearnedWavelet + Transformer**\n",
    "\n",
    "## Hip√≥tese\n",
    "Wavelets aprendidas podem adaptar-se √†s caracter√≠sticas espec√≠ficas do sinal,\n",
    "potencialmente superando wavelets fixas como db2.\n",
    "\n",
    "## Arquitetura\n",
    "```\n",
    "Input (raw signal) -> LearnedWaveletDWT1D_QMF -> [CNN/LSTM/Transformer] -> Output\n",
    "```\n",
    "\n",
    "A camada LearnedWaveletDWT1D_QMF aprende os filtros low/high pass durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3673466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, Conv1D, MaxPooling1D, LSTM,\n",
    "    Flatten, BatchNormalization, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Imports locais - modelos LWT\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('../../models')\n",
    "from LWT import LearnedWaveletDWT1D_QMF, LearnedWaveletPair1D_QMF\n",
    "\n",
    "from src.models import get_callbacks, TransformerBlock\n",
    "from src.evaluation import RegressionEvaluator, ResultsManager\n",
    "from src.visualization import ExperimentVisualizer\n",
    "from config.experiment_config import (\n",
    "    DATA_DIR, RESULTS_DIR, MODELS_DIR,\n",
    "    DL_TRAINING_CONFIG, LEARNED_WAVELET_CONFIG\n",
    ")\n",
    "\n",
    "# Configura√ß√£o\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "(RESULTS_DIR / \"learned_wavelet_experiments\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\n‚úÖ Imports realizados com sucesso!\")\n",
    "print(f\"\\nüì¶ LearnedWaveletDWT1D_QMF carregado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86fd41f",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb433367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar datasets (raw)\n",
    "X_train = np.load(DATA_DIR / \"X_train.npy\")\n",
    "y_train = np.load(DATA_DIR / \"y_train.npy\")\n",
    "X_val = np.load(DATA_DIR / \"X_val.npy\")\n",
    "y_val = np.load(DATA_DIR / \"y_val.npy\")\n",
    "X_test = np.load(DATA_DIR / \"X_test.npy\")\n",
    "y_test = np.load(DATA_DIR / \"y_test.npy\")\n",
    "\n",
    "# Adicionar dimens√£o de canal\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(f\"üì¶ Dados Carregados (Raw + Canal):\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Val:   {X_val.shape}\")\n",
    "print(f\"  Test:  {X_test.shape}\")\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "print(f\"\\nInput shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab581250",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o das Learned Wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab22b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o da wavelet aprendida\n",
    "wavelet_config = LEARNED_WAVELET_CONFIG.copy()\n",
    "\n",
    "print(\"Configura√ß√£o LearnedWaveletDWT1D_QMF:\")\n",
    "for k, v in wavelet_config.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Gerenciadores\n",
    "results_manager = ResultsManager(RESULTS_DIR / \"learned_wavelet_experiments\")\n",
    "evaluator = RegressionEvaluator()\n",
    "visualizer = ExperimentVisualizer()\n",
    "\n",
    "training_config = DL_TRAINING_CONFIG.copy()\n",
    "\n",
    "# Armazenar resultados\n",
    "all_results = {}\n",
    "all_histories = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e7c1b",
   "metadata": {},
   "source": [
    "## 3. Fun√ß√µes para Criar Modelos com Learned Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad14626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learned_wavelet_cnn(input_shape, wavelet_config, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    LearnedWaveletDWT1D_QMF + CNN\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Learned Wavelet Layer\n",
    "    wavelet = LearnedWaveletDWT1D_QMF(\n",
    "        levels=wavelet_config.get('levels', 3),\n",
    "        kernel_size=wavelet_config.get('kernel_size', 32),\n",
    "        wavelet_net_units=wavelet_config.get('wavelet_net_units', 32),\n",
    "        mode=\"concat\",\n",
    "        reg_energy=wavelet_config.get('reg_energy', 1e-2),\n",
    "        reg_high_dc=wavelet_config.get('reg_high_dc', 1e-2),\n",
    "        reg_smooth=wavelet_config.get('reg_smooth', 1e-3),\n",
    "    )\n",
    "    x = wavelet(inputs)\n",
    "    \n",
    "    # CNN layers\n",
    "    x = Conv1D(64, 7, activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, 5, activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(256, 3, activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='LearnedWavelet_CNN')\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_learned_wavelet_lstm(input_shape, wavelet_config, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    LearnedWaveletDWT1D_QMF + LSTM\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Learned Wavelet Layer\n",
    "    wavelet = LearnedWaveletDWT1D_QMF(\n",
    "        levels=wavelet_config.get('levels', 3),\n",
    "        kernel_size=wavelet_config.get('kernel_size', 32),\n",
    "        wavelet_net_units=wavelet_config.get('wavelet_net_units', 32),\n",
    "        mode=\"concat\",\n",
    "        reg_energy=wavelet_config.get('reg_energy', 1e-2),\n",
    "        reg_high_dc=wavelet_config.get('reg_high_dc', 1e-2),\n",
    "        reg_smooth=wavelet_config.get('reg_smooth', 1e-3),\n",
    "    )\n",
    "    x = wavelet(inputs)\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = LSTM(128, return_sequences=True, dropout=0.3, kernel_regularizer=l2(0.001))(x)\n",
    "    x = LSTM(64, return_sequences=False, dropout=0.3, kernel_regularizer=l2(0.001))(x)\n",
    "    \n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='LearnedWavelet_LSTM')\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_learned_wavelet_transformer(input_shape, wavelet_config, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    LearnedWaveletDWT1D_QMF + Transformer\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Learned Wavelet Layer\n",
    "    wavelet = LearnedWaveletDWT1D_QMF(\n",
    "        levels=wavelet_config.get('levels', 3),\n",
    "        kernel_size=wavelet_config.get('kernel_size', 32),\n",
    "        wavelet_net_units=wavelet_config.get('wavelet_net_units', 32),\n",
    "        mode=\"concat\",\n",
    "        reg_energy=wavelet_config.get('reg_energy', 1e-2),\n",
    "        reg_high_dc=wavelet_config.get('reg_high_dc', 1e-2),\n",
    "        reg_smooth=wavelet_config.get('reg_smooth', 1e-3),\n",
    "    )\n",
    "    x = wavelet(inputs)\n",
    "    \n",
    "    # Proje√ß√£o para dimens√£o do transformer\n",
    "    x = Dense(64 * 4)(x)\n",
    "    \n",
    "    # Transformer blocks\n",
    "    x = TransformerBlock(head_size=64, num_heads=4, ff_dim=128, dropout=0.2)(x)\n",
    "    x = TransformerBlock(head_size=64, num_heads=4, ff_dim=128, dropout=0.2)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='LearnedWavelet_Transformer')\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de cria√ß√£o de modelos definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7974635",
   "metadata": {},
   "source": [
    "## 4. Experimento 1: LearnedWavelet + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéì Experimento: LearnedWaveletDWT1D_QMF + CNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Criar modelo\n",
    "model_lwt_cnn = create_learned_wavelet_cnn(input_shape, wavelet_config)\n",
    "model_lwt_cnn.summary()\n",
    "\n",
    "# Callbacks\n",
    "model_path = str(MODELS_DIR / \"learned_wavelet_cnn_best.keras\")\n",
    "callbacks = get_callbacks(model_path, patience_early=15, patience_lr=7)\n",
    "\n",
    "# Treinar\n",
    "t0 = time.time()\n",
    "history_lwt_cnn = model_lwt_cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=training_config['epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_lwt_cnn = model_lwt_cnn.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# M√©tricas\n",
    "lwt_cnn_metrics = evaluator.evaluate(y_test, y_pred_lwt_cnn)\n",
    "\n",
    "print(f\"\\nüìä Resultados LearnedWavelet + CNN:\")\n",
    "print(f\"  RMSE: {lwt_cnn_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {lwt_cnn_metrics['mae']:.6f}\")\n",
    "print(f\"  R¬≤:   {lwt_cnn_metrics['r2']:.6f}\")\n",
    "print(f\"  Tempo: {elapsed:.2f}s\")\n",
    "\n",
    "all_results['LearnedWavelet_CNN'] = {\n",
    "    'metrics': lwt_cnn_metrics,\n",
    "    'time': elapsed,\n",
    "    'epochs': len(history_lwt_cnn.history['loss']),\n",
    "    'y_pred': y_pred_lwt_cnn,\n",
    "    'model': model_lwt_cnn,\n",
    "    'params': model_lwt_cnn.count_params()\n",
    "}\n",
    "all_histories['LearnedWavelet_CNN'] = history_lwt_cnn.history\n",
    "\n",
    "results_manager.log_experiment(\n",
    "    'DL_LearnedWavelet', 'CNN', lwt_cnn_metrics,\n",
    "    {'wavelet_config': wavelet_config}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcfe228",
   "metadata": {},
   "source": [
    "## 5. Experimento 2: LearnedWavelet + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f220afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéì Experimento: LearnedWaveletDWT1D_QMF + LSTM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Criar modelo\n",
    "model_lwt_lstm = create_learned_wavelet_lstm(input_shape, wavelet_config)\n",
    "model_lwt_lstm.summary()\n",
    "\n",
    "# Callbacks\n",
    "model_path = str(MODELS_DIR / \"learned_wavelet_lstm_best.keras\")\n",
    "callbacks = get_callbacks(model_path, patience_early=15, patience_lr=7)\n",
    "\n",
    "# Treinar\n",
    "t0 = time.time()\n",
    "history_lwt_lstm = model_lwt_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=training_config['epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_lwt_lstm = model_lwt_lstm.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# M√©tricas\n",
    "lwt_lstm_metrics = evaluator.evaluate(y_test, y_pred_lwt_lstm)\n",
    "\n",
    "print(f\"\\nüìä Resultados LearnedWavelet + LSTM:\")\n",
    "print(f\"  RMSE: {lwt_lstm_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {lwt_lstm_metrics['mae']:.6f}\")\n",
    "print(f\"  R¬≤:   {lwt_lstm_metrics['r2']:.6f}\")\n",
    "\n",
    "all_results['LearnedWavelet_LSTM'] = {\n",
    "    'metrics': lwt_lstm_metrics,\n",
    "    'time': elapsed,\n",
    "    'epochs': len(history_lwt_lstm.history['loss']),\n",
    "    'y_pred': y_pred_lwt_lstm,\n",
    "    'model': model_lwt_lstm,\n",
    "    'params': model_lwt_lstm.count_params()\n",
    "}\n",
    "all_histories['LearnedWavelet_LSTM'] = history_lwt_lstm.history\n",
    "\n",
    "results_manager.log_experiment(\n",
    "    'DL_LearnedWavelet', 'LSTM', lwt_lstm_metrics,\n",
    "    {'wavelet_config': wavelet_config}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458acb1c",
   "metadata": {},
   "source": [
    "## 6. Experimento 3: LearnedWavelet + Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéì Experimento: LearnedWaveletDWT1D_QMF + Transformer\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Criar modelo\n",
    "model_lwt_transformer = create_learned_wavelet_transformer(input_shape, wavelet_config)\n",
    "model_lwt_transformer.summary()\n",
    "\n",
    "# Callbacks\n",
    "model_path = str(MODELS_DIR / \"learned_wavelet_transformer_best.keras\")\n",
    "callbacks = get_callbacks(model_path, patience_early=15, patience_lr=7)\n",
    "\n",
    "# Treinar\n",
    "t0 = time.time()\n",
    "history_lwt_transformer = model_lwt_transformer.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=training_config['epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_lwt_transformer = model_lwt_transformer.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# M√©tricas\n",
    "lwt_transformer_metrics = evaluator.evaluate(y_test, y_pred_lwt_transformer)\n",
    "\n",
    "print(f\"\\nüìä Resultados LearnedWavelet + Transformer:\")\n",
    "print(f\"  RMSE: {lwt_transformer_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {lwt_transformer_metrics['mae']:.6f}\")\n",
    "print(f\"  R¬≤:   {lwt_transformer_metrics['r2']:.6f}\")\n",
    "\n",
    "all_results['LearnedWavelet_Transformer'] = {\n",
    "    'metrics': lwt_transformer_metrics,\n",
    "    'time': elapsed,\n",
    "    'epochs': len(history_lwt_transformer.history['loss']),\n",
    "    'y_pred': y_pred_lwt_transformer,\n",
    "    'model': model_lwt_transformer,\n",
    "    'params': model_lwt_transformer.count_params()\n",
    "}\n",
    "all_histories['LearnedWavelet_Transformer'] = history_lwt_transformer.history\n",
    "\n",
    "results_manager.log_experiment(\n",
    "    'DL_LearnedWavelet', 'Transformer', lwt_transformer_metrics,\n",
    "    {'wavelet_config': wavelet_config}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f1fbc",
   "metadata": {},
   "source": [
    "## 7. Visualiza√ß√£o dos Filtros Aprendidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df90f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair e visualizar filtros aprendidos do melhor modelo\n",
    "def extract_learned_filters(model):\n",
    "    \"\"\"Extrai os filtros aprendidos da camada wavelet.\"\"\"\n",
    "    for layer in model.layers:\n",
    "        if 'learned_wavelet' in layer.name.lower():\n",
    "            # Obter os pares wavelet\n",
    "            pairs = layer.pairs\n",
    "            filters_info = []\n",
    "            for i, pair in enumerate(pairs):\n",
    "                # Gerar filtros\n",
    "                t = pair._make_t()\n",
    "                scale = tf.nn.softplus(pair.raw_scale) + 1e-3\n",
    "                t_adj = (t - pair.translation) / scale\n",
    "                \n",
    "                z = pair.base_net(t_adj)\n",
    "                h = pair.low_head(z)\n",
    "                h = pair._normalize_h(h)\n",
    "                g = pair._qmf_from_h(h)\n",
    "                \n",
    "                filters_info.append({\n",
    "                    'level': i + 1,\n",
    "                    'low_pass': h.numpy().flatten(),\n",
    "                    'high_pass': g.numpy().flatten(),\n",
    "                    'scale': scale.numpy(),\n",
    "                    'translation': pair.translation.numpy()\n",
    "                })\n",
    "            return filters_info\n",
    "    return None\n",
    "\n",
    "# Usar o modelo CNN para visualiza√ß√£o\n",
    "filters = extract_learned_filters(all_results['LearnedWavelet_CNN']['model'])\n",
    "\n",
    "if filters:\n",
    "    n_levels = len(filters)\n",
    "    fig, axes = plt.subplots(n_levels, 2, figsize=(14, 4*n_levels))\n",
    "    \n",
    "    for i, filt in enumerate(filters):\n",
    "        # Low-pass filter\n",
    "        axes[i, 0].plot(filt['low_pass'], 'b-', linewidth=2)\n",
    "        axes[i, 0].set_title(f'N√≠vel {filt[\"level\"]} - Filtro Low-Pass (h)')\n",
    "        axes[i, 0].set_xlabel('Coeficiente')\n",
    "        axes[i, 0].set_ylabel('Amplitude')\n",
    "        axes[i, 0].grid(True, alpha=0.3)\n",
    "        axes[i, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # High-pass filter\n",
    "        axes[i, 1].plot(filt['high_pass'], 'r-', linewidth=2)\n",
    "        axes[i, 1].set_title(f'N√≠vel {filt[\"level\"]} - Filtro High-Pass (g) [QMF]')\n",
    "        axes[i, 1].set_xlabel('Coeficiente')\n",
    "        axes[i, 1].set_ylabel('Amplitude')\n",
    "        axes[i, 1].grid(True, alpha=0.3)\n",
    "        axes[i, 1].axhline(y=0, color='b', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.suptitle('Filtros Wavelet Aprendidos (LearnedWaveletDWT1D_QMF)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / \"learned_wavelet_experiments\" / \"learned_filters.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Par√¢metros dos Filtros Aprendidos:\")\n",
    "    for filt in filters:\n",
    "        print(f\"  N√≠vel {filt['level']}: scale={filt['scale']:.4f}, translation={filt['translation']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è N√£o foi poss√≠vel extrair os filtros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbee051",
   "metadata": {},
   "source": [
    "## 8. Compara√ß√£o dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame comparativo\n",
    "comparison_data = []\n",
    "for model_name, result in all_results.items():\n",
    "    row = {\n",
    "        'Model': model_name,\n",
    "        'RMSE': result['metrics']['rmse'],\n",
    "        'MAE': result['metrics']['mae'],\n",
    "        'R¬≤': result['metrics']['r2'],\n",
    "        'Params': result['params'],\n",
    "        'Time (s)': result['time'],\n",
    "        'Epochs': result['epochs']\n",
    "    }\n",
    "    comparison_data.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä COMPARA√á√ÉO - Modelos com LearnedWaveletDWT1D_QMF\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Salvar\n",
    "comparison_df.to_csv(RESULTS_DIR / \"learned_wavelet_experiments\" / \"comparison_learned_wavelet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eec7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o comparativa\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics_to_plot = ['RMSE', 'MAE', 'R¬≤']\n",
    "colors = plt.cm.Purples(np.linspace(0.4, 0.9, len(comparison_df)))\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    data = comparison_df.set_index('Model')[metric].sort_values(\n",
    "        ascending=(metric != 'R¬≤')\n",
    "    )\n",
    "    bars = axes[idx].barh(data.index, data.values, color=colors)\n",
    "    axes[idx].set_xlabel(metric)\n",
    "    axes[idx].set_title(f'Compara√ß√£o: {metric}')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    for bar, val in zip(bars, data.values):\n",
    "        axes[idx].text(val, bar.get_y() + bar.get_height()/2,\n",
    "                      f'{val:.4f}', va='center', ha='left', fontsize=9)\n",
    "\n",
    "plt.suptitle('Learned Wavelet (LearnedWaveletDWT1D_QMF)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"learned_wavelet_experiments\" / \"comparison_learned_wavelet.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2305d",
   "metadata": {},
   "source": [
    "## 9. An√°lise de Predi√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise do melhor modelo\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_result = all_results[best_model_name]\n",
    "\n",
    "print(f\"\\nüèÜ Melhor Modelo: {best_model_name}\")\n",
    "\n",
    "# Plot de predi√ß√µes\n",
    "fig = visualizer.plot_prediction_comparison(\n",
    "    y_test, best_result['y_pred'],\n",
    "    model_name=best_model_name,\n",
    "    n_samples=500,\n",
    "    save_path=RESULTS_DIR / \"learned_wavelet_experiments\" / f\"predictions_{best_model_name}.png\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf928b28",
   "metadata": {},
   "source": [
    "## 10. Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã RESUMO - Experimentos com Learned Wavelets\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n‚úÖ Modelos avaliados: {len(all_results)}\")\n",
    "print(f\"‚úÖ Melhor modelo: {best_model_name}\")\n",
    "print(f\"‚úÖ Melhor RMSE: {comparison_df.iloc[0]['RMSE']:.6f}\")\n",
    "print(f\"‚úÖ Melhor R¬≤: {comparison_df.iloc[0]['R¬≤']:.6f}\")\n",
    "print(f\"\\nüìÅ Resultados salvos em: {RESULTS_DIR / 'learned_wavelet_experiments'}\")\n",
    "print(\"\\nüéâ Notebook conclu√≠do com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
